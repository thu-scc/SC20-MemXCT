# Run scripts

## Assumption

These scripts expects datasets to be put into the same level as ReproducibilityChallenge directory:

```
..
├── ReproducibilityChallenge
│   ├── compile
│   ├── run
│   ├── ...
├── datasets
│   ├── ADS1_sinogram.bin
│   ├── ADS1_theta.bin
│   ├── ADS2_sinogram.bin
│   ├── ADS2_theta.bin
│   ├── ADS3_sinogram.bin
│   ├── ADS3_theta.bin
│   ├── ADS4_sinogram.bin
│   ├── ADS4_theta.bin
│   ├── CDS1_sinogram.bin
│   ├── CDS1_theta.bin
│   ├── CDS2_sinogram.bin
│   ├── CDS2_theta.bin
│   ├── CDS3_sinogram.bin
│   └── CDS3_theta.bin
├── ...
```

## Common Scripts

There are three scripts in the top directory.

1. `para.sh`: This script set environment variables for memxct. It will be called by other scripts. Do not use it drectly.
2. `cluster_init.sh`: It sets up the system environment for a newly-loaded Azure VM. For a cluster managed by slurm, it can be called as `srun -n $NODE_NUM ./cluster_init.sh` to set up system environment for all nodes. Note that there is a hardcoding IP addresss written in it, which refers to the NFS server IP. The IP may be changed according to the NFS IP.
3. `run_stream.sh`: It measures the memory bandwidth for CPU by STREAM benchmark. To measure a single CPU socket, run `OMP_NUM_THREADS=$CORE_PER_CPU; taskset -c $CPU_LIST ./run_stream.sh`. The output will show in stdout, so redirect it to the proper output directory.



## Single CPU experiment

To run single CPU experiment, go to `single_cpu` directory. It contains the following scripts:

- collect.sh: Collect environment info, including Azure metadata, CPU and GPU models, software and hardware infomation.
- manual_run.cpu.sh: Run memxct.cpu.
- cpu_grid_search.py: Enumerate different combinations of parameters and run manaual_run.cpu.sh.

The `manual_run.cpu.sh` script expects five arguments:

1. NTHREAD: Number of OpenMP threads to use
2. DATA: Can be one of: ADS[1-4], CDS[1-3]
3. SPATSIZE/SPECSIZE: Tile size
4. PROJBLOCK/BACKBLOCK: Block size
5. PROJBUFF/BACKBUFF: Buffer size

For example, the following line:

```shell
./manual_run.cpu.sh 40 ADS2 256 128 64
```

...will run one MPI process with 40 OpenMP threads. It uses ADS2 dataset and uses 256 as tile size, 128 as block size and 64 as buffer size respectively.

We have run single_cpu tests under F16s_v2(Intel) and HB60rs(AMD) SKUs. Output is provided at `run/output/single_cpu/single_{amd,intel}`. Each directory contains:

- NTHREAD.DATA.SPATSIZE.SPECSIZE.PROJBLOCK.BACKBLOCK.PROJBUFF.BACKBUFF.bin: Reconstructed tomogram
- NTHREAD.DATA.SPATSIZE.SPECSIZE.PROJBLOCK.BACKBLOCK.PROJBUFF.BACKBUFF.out: Process output
- env-output.txt: Environment info generated by collect.sh
- stream_result.txt: STREAM memory bandwidth result generated by STREAM benchmark

We also use `cpu_grid_search.py` to search for optimal parameters:

```shell
python3 cpu_grid_search.py --script manual_run.cpu.sh --thread $THREAD --tile_size $TILE_SIZE
```

It will enumerate parameters and run `manual_run.cpu.sh` many times.

On F16s_v2(Intel) machine, we use 16 cores in one socket and on HB60rs(AMD) machine, we use 30 cores in one socket. Thus, we run one MPI process and 16/30 threads respectively.

Timings are reported by MemXCT itself and timing data is extracted from its text output by scripts under `figures/scripts`.

## Single GPU experiment

To run single GPU experiment, go to `single_gpu` directory. It's very similar to `single_cpu` directory, except:

1. There is an extra arg for `manual_run.gpu.sh`: `./manual_run.gpu.sh $GPU $NTHREAD $DATA $TILE_SIZE $BLOCK_SIZE $BUFFER_SIZE` where `GPU` can be one of: k80, p100 and v100.
2. The `gpu_grid_search.py` needs an extra argument `--gpu $GPU`
3. Output files are put under `single_k80`, `single_p100` and `single_v100` respectively.

For example, the following line:

```shell
./manual_run.gpu.sh v100 16 ADS2 256 128 64
```

...will run one MPI process for one v100 with 16 OpenMP threads. It uses ADS2 dataset and uses 256 as tile size, 128 as block size and 64 as buffer size respectively. Note that `CUDA_VISIBLE_DEVICES` has been set to 0 in this script, so it can work in a multi-gpu system.


We use NC24r_Promo for K80, NC24rs_v2 for P100 and NC24rs_v3 for V100. Environment info of these SKU is put under corresponding directories.

## Strong scaling on CPU

Scripts for strong scaling on CPU are put under `strong_scaling_on_cpu` directory.

There are three scripts:

- manual_run.intel.cpu.sh: Top level script, which uses mpirun to launch jobs in one, two and four nodes
- inner.sh: Wrapper script for mpirun, which setups parameters for MemXCT
- collect.sh: Environment info collection

The `manual_run.intel.cpu.sh` expects seven args:

1. CPU_PER_NODE: Number of CPU sockets per node
2. NTHREAD: Number of CPU cores per socket
3. HOSTFILE: A host file consisting of hostnames
4. DATA: One of ADS[1-4] or CDS[1-3]
5. SPATSIZE/SPECSIZE: Tile size
6. PROJBLOCK/BACKBLOCK: Block size
7. PROJBUFF/BACKBUFF: Buffer size

We use Slurm to allocate nodes in one group, and then use `mpi -hostfile hostfile` to distribute jobs to nodes manually instead of using `srun`.

In each node, we run $CPU_PER_NODE MPI processes and each MPI process has $NTHREAD OpenMP threads. We use F16s_v2 machine, so $CPU_PER_NODE is always 1 and $NTHREAD is 16. Intel MPI is used in this stage.

Output files are put under `run/output/strong_scaling_on_cpu` and files have the following naming convention:

- NNODE.NTHREAD.DATA.SPATSIZE.SPECSIZE.PROJBLOCK.BACKBLOCK.PROJBUFF.BACKBUFF.bin: Reconstructed tomogram
- NNODE.NTHREAD.DATA.SPATSIZE.SPECSIZE.PROJBLOCK.BACKBLOCK.PROJBUFF.BACKBUFF.out: Process output
- env-output.txt: Environment info generated by collect.sh

## Strong scaling on GPU

Scripts for strong scaling on GPU are put under `strong_scaling_on_cpu` directory. It is similar to strong scaling on CPU, but with these differences:

1. OpenMPI is used for MPI implementation
2. `manual_run.openmpi.sh` expects an argument for GPU model
3. Output file name is prepended by `$GPU` and `$NNODE` is replaced by `$NTASK`(equals to the number of gpu)

In this stage, we use NC24rs_v2 machine, which each contains 4 P100 GPU cards.Specifically, we use 1-to-1 mapping for MPI process to GPU, so 4 MPI processes are run in one node. The script uses mpirun to run on one, two and four nodes, using four, eight and sixteen P100 GPU cards respectively.

Environment info is put under `env-output.txt`.


## Visualization

Scripts for visualization are put under `visualization` directory. It is simliar to strong scaling on CPU, but with these differences.

1. OpenMPI is used for MPI implementation
2. `manual_run.amd.cpu.sh` expects and argument for iteration num
3. Output file name is prepended by `$ITER`

In this stage, we use `manual_run.amd.cpu.sh` to get the high-quality reconstructed tomogram for CDS3 because normal CPU nodes and GPU nodes do not have enough memory. The result for CDS1 and CDS2 just comes from previous results by `cp`

In summary, there are seven files in the output directory `run/output/visualization`

1. `24.60.CDS3.64.64.1024.1024.32.32.{bin, out}`: The two files are generated by the script in visualization directory. The name means we use 24 iterations, 60 OpenMP threads, CDS3 dataset, 64 tile size, 1024 block size and 32Kb buffer size to execute memxct.
2. `v100.12.CDS1.128.128.512.512.48.48.{bin, out}`: They are same as those in `run/single_gpu/single_v100`.
3. `v100.24.CDS2.128.128.512.512.48.48.{bin, out}`: They are same as those in `run/single_gpu/single_v100`.
4. `env-output.txt`: This is generated by `collect.sh` and shows the environment.


